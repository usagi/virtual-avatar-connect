<!DOCTYPE html>
<meta charset="utf-8">
<title>VAC:Virtual Avatar Connect</title>

<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=M+PLUS+Rounded+1c:wght@500&display=swap" rel="stylesheet">
<link rel="stylesheet" href="index.css">

<script type="module" src="index.js"></script>

<div class="top-container">
 <h1>Virtual Avatar Connect 公式サイト</h1>
 <h2>配信支援アプリ、AI疑似人格共演者、VRM制御、音声認識、画像認識、字幕、翻訳、読み上げなどなど</h2>

 <img src="image/catch.jpg" class="catch img-show">
</div>

<p class="note">ただいま現在進行系でこの公式ウェブサイトを作成しています。まずは使い方の例、ダウンロードや設定方法などの解説情報を最優先で作成いたします。</p>
<p class="note">いましばらく、公式ウェブサイトの見栄えが塩辛めの状態となりますが、近日中に映えデザインにアップデートいたします。なかのひとのリソース（＆なかのひともゲーム遊びたい都合🤣）ご理解頂ければ幸いです。</p>

<h3>🤔このアプリは何？</h3>

<ul>
 <li>Virtual Avatar Connect は「配信支援アプリ」です。おもに Twitch などのライブ配信向けに OBS Studio や Twitch Studio
  などの配信アプリでの字幕や画作りを支援するためのアプリです。</li>
 <li>もしかしなくてもデスクトップに常駐するイマジナリーふれんず/わいふ/はずばんど/etc.召喚アプリとしても使えるかもしれません。少なくとも開発者さんには想定外の用法でしたが楽しまれて下さい。</li>
 <li>「AI疑似人格による共演者の召喚」を行えます。会話したり解説してもらったり。（※<a href="https://platform.openai.com/" target="openai">OpenAI API</a>連携）
 </li>
 <li>「音声認識からの文字起こしによるテキスト入力」を行えます。</li>
 <li>「画像認識からの文字起こしによるテキスト入力」を行えます。</li>
 <li>「音声合成によるテキストの読み上げ」を行えます。（※<a href="https://coeiroink.com/" target="coeiroink">CoeiroInk</a>、<a
   href="http://chi.usamimi.info/" target="bouyomichan">棒読みちゃん</a>、<a
   href="https://support.microsoft.com/ja-jp/office/-%E8%AA%AD%E3%81%BF%E4%B8%8A%E3%81%92-%E9%9F%B3%E5%A3%B0%E5%90%88%E6%88%90%E6%A9%9F%E8%83%BD%E3%82%92%E4%BD%BF%E7%94%A8%E3%81%97%E3%81%A6%E3%83%86%E3%82%AD%E3%82%B9%E3%83%88%E3%82%92%E8%AA%AD%E3%81%BF%E4%B8%8A%E3%81%92%E3%82%8B-459e7704-a76d-4fe2-ab48-189d6b83333c"
   target="windows-tts">OSのTTS機能</a>との連携）</li>
 <li>「言語の翻訳」を行えます。（※<a href="https://script.google.com/" target="gas">Google Apps Script</a>連携）</li>
 <li>「字幕の表示」を行えます。</li>
 <li>「OBS Studio などの配信画面作りのソースとしての画作り」を行えます。(ブラウザーソース)</li>
 <li>「シーン切り替えもできなくはないです。」（Play/BRB/Loadingの切り替え機能サンプルは作ってみた。）</li>
</ul>

<h4>📅今後の機能追加の予定</h4>

<ul>
 <li>入力に応じて画面にエモートを乱舞させたり、チャットをかっこよくシュッと表示したりなどの絵作りテンプレートの充実</li>
 <li>入力画面のきれい、かわいい、かっこいい、あるいは機能的で便利なスキンの充実</li>
 <li>コメントリーダーアプリとの連携、またはアプリ内蔵機能としてTwitchのチャット取り込みに対応。</li>
 <li>VMCプロトコルに対応しVRM表示アプリへ姿勢や表情を送信可能に。（疑似人格共演者に動きをつけたり、複数のVMCアプリの入力をうまい具合に合成して自分のアバターへ出力したり。）</li>
 <li>OpenAI API に頼らない疑似人格バックエンドの対応。（GPT4かせめてGPT3.5なみのPCのGPUで動かせる何かがあれば…）</li>
 <li>外部アプリ、サービス、OS機能との自由度の高い連携の仕組みの追加。（任意のコマンドを音声から実行させるとか）</li>
</ul>

<h3>📂ダウンロード</h3>

<ul>
 <a href="https://github.com/usagi/virtual-avatar-connect/releases" target="vac_download">
  <li>usagi/virtual-avatar-connect Releases</li>
 </a>
</ul>

<h3 id="usage">📖使い方</h3>

<p>とりあえず簡易版の使い方ガイドを掲載します。きれいでかっこいいやつは数日…お待ち下さい。🙏</p>

<ul>

 <a data-scroll-to="#download-and-install">
  <li>1. ダウンロードとインストール</li>
 </a>

 <a data-scroll-to="#first-run">
  <li>2. お試し起動と動作確認</li>
 </a>

 <a data-scroll-to="#speech-recognition">
  <li>3. 「🎙️音声認識」→（テキスト）→「テキスト表示」</li>
 </a>

 <a data-scroll-to="#image-recognition">
  <li>4. 「🖼️画像認識」→（テキスト）→「テキスト表示」 // 入力画面でお手軽編</li>
 </a>

 <a data-scroll-to="#image-recognition-processor">
  <li>5. 「🖼️画像認識」→（テキスト）→「テキスト表示」 // プロセッサー編</li>
 </a>

 <a data-scroll-to="#text-to-speech-os-tts">
  <li>6. （テキスト）→「音声合成🗣️」 // OS-TTS編</li>
 </a>

 <a data-scroll-to="#text-to-speech-coeiroink">
  <li>7. （テキスト）→「音声合成🗣️」 // CoeiroInk編</li>
 </a>

 <a data-scroll-to="#text-to-speech-bouyomichan">
  <li>8. （テキスト）→「音声合成🗣️」 // 棒読みちゃん編</li>
 </a>

 <a data-scroll-to="#language-translation-gas">
  <li>9. （テキスト）→「言語翻訳🗺️」→「テキスト表示」 // GAS編</li>
 </a>

 <a data-scroll-to="#ai-pseudo-personality-openai">
  <li>10. （テキスト）→「AI疑似人格👻」→「テキスト表示」 // OpenAI編</li>
 </a>

 <a data-scroll-to="#modify">
  <li>11. （テキスト）→「MODify❣️」→（テキスト） // 内容の加工や変換を行います</li>
 </a>

 <a data-scroll-to="#output-screen">
  <li>12. 「出力画面↗️」の作り込み // 複数の出力画面をお好みでカスタムできます</li>
 </a>

 <a data-scroll-to="#input-screen">
  <li>13. 「↘️入力画面」をお好みに // 複数の入力画面をお好みでカスタムできます</li>
 </a>

 <a data-scroll-to="#system-and-keywords">
  <li>X. ふろく: VAC の仕組みと用語</li>
 </a>
</ul>

<h3>🎨スクショ</h3>

<p>ただいま撮影準備中です🙇🏼‍♀️（雰囲気は<a href="https://www.twitch.tv/usaginetwork" target="twitch">開発のなかのひとの Twitch
  配信</a>で見られるかもしれません👀）</p>

<div class="show-case"></div>

<h3>🚧開発プロジェクト</h3>

<p>VACはMITライセンスのオープンソースソフトウェアです。開発にご協力頂ける方は <a href="https://github.com/usagi/virtual-avatar-connect"
  target="vac_dev">GitHub ( https://github.com/usagi/virtual-avatar-connect )</a> へどうぞ！</p>
<p>※不具合報告やご要望は GitHub の Issues へ頂ければ幸いです。🙇🏼‍♀️</p>

<hr>








<section id="download-and-install">
 <h1>
  <a><span data-scroll-to="#usage">🔼</span></a>
  <a><span data-scroll-to="#first-run">🔽</span></a>
  使い方 1. ダウンロードとインストール
 </h1>

 <div class="flow">
  <h2>手順</h2>

  <ul>
   <li>1-1. リリース一覧ページへアクセス: <a href="https://github.com/usagi/virtual-avatar-connect/releases"
     target="vac_download">https://github.com/usagi/virtual-avatar-connect/releases</a></li>
   <li>1-2. その時点で最新っぽいものの「バージョン名」または「Assets」をクリックして添付されたファイルの一覧が表示された状態にします。†1</li>
   <li>1-3. "virtual-avatar-connect-x.x.x(-alphaやbetaが付く場合もあり).zip"をクリックしてダウンロードします。†2</li>
   <li>1-4. .zipの中身をお好みの場所へ展開します。†3</li>
  </ul>
 </div>

 <p>†1: 例えばこういうファイルです: <img src="image/m01/dl-file.png" class="img-show"></p>
 <p>†2: お使いのブラウザによっては「ブロック・一般的ではないファイル」または他の警告が表示され、ファイルのダウンロードに追加の操作が必要な場合があります。右上の方にある小さな▶をクリックすると「ダウンロードを続行」できます。</p>
 <div class="left-to-right-flex gap-1em">
  <img src="image/m01/dl-blocking.png" class="img-show">
  <span>⇨</span>
  <img src="image/m01/dl-continue.png" class="img-show">
 </div>
 <p>†3:
  デスクトップやマイドキュメントでも構いませんし、"C:\Virtual-Avatar-Connect"や"D:\ProgramData\Virtual-Avatar-Connect"でも構いません。よくわからない場合はとりあえずデスクトップにでも展開して使ってみて下さい。展開されたファイル中の
  "virtual-avatar-connect.exe" が VAC の実行ファイルです。お好みでショートカットも作成してお使いになると便利かもしれません。
  <img src="image/m01/decompressed.png" class="img-show">
 <p class="note">お使いの環境によっては .exe の部分が表示されていないかもしれません。<a
   class="search">ファイルの拡張子を表示する方法</a>などで検索してお使いの環境でのファイル操作についてお調べ下さい。🙏）</p>
 </p>

</section>

<section id="first-run">
 <h1>
  <a><span data-scroll-to="#download-and-install">🔼</span></a>
  <a><span data-scroll-to="#speech-recognition">🔽</span></a>
  使い方 2. お試し起動と動作確認
 </h1>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>2-1. "virtual-avatar-connect.exe" を直接、またはお好みで作成したショートカットなどから起動します。</li>
   <li>2-2. ブラウザーで標準の入力画面 <a href="http://127.0.0.1:57000/input" target="_blank">http://127.0.0.1:57000/input</a>
    または標準の出力画面 <a href="http://127.0.0.1:57000/output">http://127.0.0.1:57000/output</a> にアクセスします。</li>
   <li>2-3. それらしい画面が表示されていれば動作確認は成功です。</li>
   <li>2-4. 初期状態の設定ファイルでは《コマンド》プロセッサーを含むすべてのプロセッサーが無効化されているため、何か素敵な方法でVACを終了させる手段はありません。VAC本体が動作している"クロイガメン"で CTRL + C
    キーを押すか、それが動作しているウィンドウの閉じるボタンを押して VAC を終了させましょう。</li>
   <li>2-5. (2-2.)で表示した入力画面または出力画面をリロードして、表示されなくなっていれば VAC は終了できています。</li>
  </ul>
 </div>

 <div>参考:
  <img src="image/m02/overview.jpg" class="img-show">
  <p>設定ファイルや必須フォルダーの構成に問題がなく無事に起動に成功すると、②のような "クロイガメン" が表示されます。
  <p class="note">環境によってはウィンドウの枠などの様子が異なるかもしれません。</p>
  <p class="note">初期配布に付属の設定では前回までの動作状態の一部が保存される設定になっていますが、初回起動時はまだファイルが存在しないため "WARN"
   （警告）が表示されますが、問題ありません。</p>
 </div>

</section>








<section id="speech-recognition">
 <h1>
  <a><span data-scroll-to="#first-run">🔼</span></a>
  <a><span data-scroll-to="#image-recognition">🔽</span></a>
  使い方 3. 「音声認識」→（テキスト）→「テキスト表示」
 </h1>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>3-1. VAC を起動します。 </li>
   <li>3-2. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a class="url">http://127.0.0.1:57000/input</a> を開きます。</li>
   <li>3-3. ブラウザーの別のウィンドウまたはタブへ標準の出力画面 <a class="url">http://127.0.0.1:57000/output</a> を開きます。
   </li>
   <li class="hr"></li>
   <li>3-4. 入力画面の上部の「音声認識(１回)」のチェックを ON にします。†1†2</li>
   <li>3-5. マイクなどから音声を認識すると認識されたテキストが1回だけ表示されます。</li>
   <li>3-6. 認識されたテキストが表示された入力欄の右側にある「POST」ボタンを押すとテキストを VAC へ入力できます。†3†4</li>
  </ul>
 </div>

 <p>†1: 「音声認識(1回)」は ON にすると1回(1文)だけ音声認識が動作します。音声から認識されたテキストは横長の部分に表示されます。
  <img src="image/m03/input-voice.png" class="img-show" style="max-width: 40%">
 </p>

 <p class="note">†2: 初めて音声入力へアクセスする際にブラウザーがマイクの使用許可を表示する場合があります。許可すると音声入力が可能になります。 </p>

 <div class="left-to-right-flex gap-1em">
  <img src="image/m03/allow-mic.png" class="img-show">
  <span>⇨</span>
  <img src="image/m03/rec.png" class="img-show">
 </div>

 <p class="info">音声入力を行う言語を変更したい場合は「認識言語」の入力欄を "ja-JP" から "en-US" や "fr-FR" に変更します。（言語と地域のコードは<a
   class="search">ISO396</a>と<a class="search">ISO3166</a>の組み合わせです。）</p>
 </p>

 <p>†3
  手順では紹介していませんが「音声認識(常時)」を ON にした場合は OFF にするまでずっと音声を認識し続けます。
  動作試験や、特定のタイミングでのみ音声入力したい場合は「音声認識(1回)」を使い、配信中に全自動で入力し続けたい場合などは「音声認識(常時)」を使うと便利です。
 </p>

 <p>†4
  また、「認識結果を自動入力」を ON にすると、認識されたテキストが自動的に VAC チャンネルへ送信されるようになります。手動で送信したい場合は POST ボタンを使用します。
  初期状態では送信先のチャンネルは user が設定されています。入力画面からの送信先は POST ボタンの左側の入力欄から任意に送信先のチャンネルを変更できます。
 </p>

 <p>
  VAC は入力画面などから入力された《コンテント》を《チャンネル》へ流し、《プロセッサー》で処理し、出力画面や音声合成エンジンへ送出します。
  出力画面では特定の《チャンネル》の《コンテント》を表示できます。手順にはありませんが、ここで試したくなった場合は出力画面を表示した状態で、
  入力画面の POST ボタンの左側の送信先チャンネル設定を title あるいは description に変更した状態でテキストを送信してみましょう。👀
 </p>

 <img src="image/m03/title-and-description.jpg" class="img-show" style="max-width: 100%">

</section>








<section id="image-recognition">
 <h1>
  <a><span data-scroll-to="#speech-recognition">🔼</span></a>
  <a><span data-scroll-to="#image-recognition-processor">🔽</span></a>
  使い方 4. 「画像認識」→（テキスト）→「テキスト表示」 // 入力画面でお手軽編
 </h1>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>4-1. VAC を起動します。 </li>
   <li>4-2. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a class="url">http://127.0.0.1:57000/input</a> を開きます。</li>
   <li>4-3. ブラウザーの別のウィンドウまたはタブへ標準の出力画面 <a class="url">http://127.0.0.1:57000/output</a> を開きます。
   </li>
   <li class="hr"></li>
   <li>4-4. 入力画面の下部の「画像認識(１回)」のチェックを ON にします。†1</li>
   <li>4-5. 文字が写るスクショをクリップボードへ撮影し（Windows:<a class="search">Win+Shift+S</a>）、
    入力画面の "Paste or Drop image here -> Recognize the Text" と書かれたあたりへ貼り付け（Windows:<a class="search">CTRL+V</a>） します。
    認識されたテキストが1回だけ表示されます。†2</li>
   <li>4-6. 認識されたテキストが表示された入力欄の右側にある「POST」ボタンを押すとテキストを VAC へ入力できます。</li>
  </ul>
 </div>

 <p>†1:「画像認識(１回)」のチェックを ON にした状態の入力画面の画面下部の画像認識機能の様子。
  <img src="image/m04/input-voice.png" class="img-show" style="max-width: 100%">
 </p>

 <p>†2: 画像認識でテキストが認識完了した状態の様子。(この例で使ったのは <a href="https://www.arknights.jp/" target="arknights">Arknights</a>
  というゲームのとあるイベントの会話の一節です。)
  <img src="image/m04/image-recognized.jpg" class="img-show" style="max-width: 100%">
 </p>

 <p class="info">
  VACの標準の入力画面でのお手軽ばーじょんの画像認識機能では、画像の「クリップボードからの貼り付け」と「ファイルのドラッグ・アンド・ドロップによる貼り付け」に対応しています。
 </p>

 <p class="info">
  プレイ中のゲーム画面からスクショをさっとクリップボードへ撮影し、クリップボードからそのまま VAC へ貼り付けられるようになっています。
  読み方のわからない漢字やことばをテキスト化して検索しやすくしたり、VAC へ入力して AI 疑似人格に調べて貰ったり、音声合成で読み上げて貰ったり、とっさに使えて便利かもしれません。
 </p>

 <p class="note">
  あらかじめ認識させたい「ウィンドウのタイトル」や「会話などで繰り返し表示される文字がでてくる領域」がある場合は、
  次の【使い方 5. 「画像認識」→（テキスト）→「テキスト表示」 // プロセッサー編】で紹介する「プロセッサー版」の画像認識機能を使うと便利な場合もあります。
 </p>

 <p class="note">
  もし、画像認識の結果が悪い場合は、認識させたい文字の言語が「認識言語」の入力欄に設定されているか確認して見て下さい。
  日本語なら "jpn" 英語なら "eng" フランス語なら "fra" のように設定します。この機能の言語コードの一覧は「lang code」と書かれたリンクをクリックすると表示できます。
 </p>

</section>








<section id="image-recognition-processor">
 <h1>
  <a><span data-scroll-to="#image-recognition">🔼</span></a>
  <a><span data-scroll-to="#text-to-speech-os-tts">🔽</span></a>
  使い方 5. 「画像認識」→（テキスト）→「テキスト表示」 // プロセッサー編
 </h1>

 <p class="info">
  今回は 《Screenshot》 Processor と 《OCR》 Processor を使用します。Processor は VAC に内蔵された入力と出力の間で流れる内容を変換したり、調整したりする主要な仕組みです。
  Processor を自由に組み合わせることでお好みのカスタム設定でVACを楽しめます。
 </p>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>5-1. 《Screenshot》と《OCR》のシンプルな設定例の設定ファイル "conf.example-ss-ocr.toml" を "virtual-avatar-connect.exe" へドロップして VAC
    を起動してみましょう。
    <p class="info">
     コマンドラインでは `./virtual-avatar-connect conf.example-ss-ocr.toml` です。コマンドラインでの使い方は `--help` で確認できます。
    </p>
    <p>この設定ファイル "conf.example-ss-ocr.toml" の中身はこうなっています。👀</p>
    <textarea class="code" readonly style="height:41em"># ← これを書いた行は「コメント」になります。設定ファイルの中にメモを書き残したいときに使うと便利です。
# スクリーンショット(ウィンドウのスクショを撮影→ファイルに保存してファイルパスを送信)

# ↓ これを書くと「ここから特定のプロセッサーの設定をはじめるよ」という意味になります。
[[processors]]
# 「今回は "screenshot" タイプのプロセッサーを使うよ」という意味になります。
feature = "screenshot"
# 着信を受け取るチャンネル名
channel_from = "ss"
# 結果を出力するチャンネル名
channel_to = "ocr"
# スクショを撮影したいウィンドウのタイトルに含まれる文字列を記入します
# とりあえずシンプルな「メモ帳」などで試してみましょう。
# この設定項目では . ? * ( ) \ $ ^ などの文字は特別な用途(正規表現)で使われるので、よくわからなければ今はそうした文字が入らない設定を試してみましょう。
title_regex = "ここにキャプチャーしたいウィンドウのタイトルに含まれる文字列を記入します"
# スクショの保存先を指定します。
paths = [ "ss.png" ]

# OCR(画像認識→テキスト)
[[processors]]
channel_from = "ocr"
channel_to = "description"
feature = "ocr"
# 日本語の文字を読み取りたい場合は "ja_JP" 、USA英語なら "en_US" のように設定します。
lang = "ja_JP"
# 入力として Screenshot などチャンネルの前段階のプロセッサーが出力した内容を受け取りたい場合は true にします。
load_from_content = true</textarea>
   </li>
   <li class="hr"></li>
   <li>5-2. VAC を起動します。 </li>
   <li>5-3. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a class="url">http://127.0.0.1:57000/input</a> を開きます。</li>
   <li>5-4. ブラウザーの別のウィンドウまたはタブへ標準の出力画面 <a class="url">http://127.0.0.1:57000/output</a> を開きます。
   </li>
   <li class="hr"></li>
   <li>5-5. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを ss に設定します。</li>
   <li>5-6. 送信チャンネルを設定した隣にある POST ボタンを押します。†2</li>
  </ul>
 </div>

 <p class="info">†1: テキストエディターを使います。特に普段使っているテキストエディターが無い場合は、<a class="search">Windows の「メモ帳」</a>でファイルを編集できれば十分です。</p>

 <div>
  <p>†2: 成功するとウィンドウから撮影されたスクショが "ss.png" として保存され、この画像から認識されたテキストが標準の出力画面のサブタイトル的な部分に表示されます。</p>
  <div class="left-to-right-flex gap-1em">
   <img src="image/m05/ss-post.png" class="img-show">
   <span>⇨</span>
   <img src="image/m05/ss-ocr-result.png" class="img-show">
  </div>
  <p>少し惜しい感じになる場合もありますが、画像からの文字列認識は必ず人間が読めるように読み取れるとは限りません。いまのところ「だいたいうまくが」くらいには成功しますので、便利な使い所を見つけてみて下さい。</p>
 </div>

 <p class="info preparing">
  《Screenshot》 Processor にはウィンドウ内の特定の領域だけをスクショする設定、1度の実行で複数の領域のスクショを撮影する設定などがあります。
  詳しくは「使い方 X. ふろく: VAC の仕組みと用語」の Processor の 《Screenshot》 の項目をご覧下さい。
 </p>

 <p class="info preparing">
  《OCR》 Processor にはウィンドウ内の特定の領域だけをスクショする設定、1度の実行で複数の領域のスクショを撮影する設定などがあります。
  詳しくは「使い方 X. ふろく: VAC の仕組みと用語」の Processor の 《OCR》 の項目をご覧下さい。
 </p>

</section>








<section id="text-to-speech-os-tts">
 <h1>
  <a><span data-scroll-to="#text-to-speech-os-tts">🔼</span></a>
  <a><span data-scroll-to="#text-to-speech-coeiroink">🔽</span></a>
  使い方 6. （テキスト）→「音声合成」 // OS-TTS編
 </h1>

 <p class="info">
  今回は 《OS-TTS》 Processor を使用します。Processor は VAC に内蔵された入力と出力の間で流れる内容を変換したり、調整したりする主要な仕組みです。
  Processor を自由に組み合わせることでお好みのカスタム設定でVACを楽しめます。
 </p>

 <div class="info">《OS-TTS》は Windows 11 などの OS に標準で付属している音声合成エンジンを使用してテキストを音声に変換します。
  <ul>
   <li>OSが対応していれば追加のソフトウェアなしで使用でき、多くの言語の音声合成に対応しています。</li>
   <li>英語をはじめとする多言語の音声を使用したい場合におすすめです。</li>
   <li>もちろん日本語の音声も合成できますが、OSによっては少し不自然でぎこちないかもしれません。</li>
  </ul>
 </div>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>6-1. 《OS-TTS》のシンプルな設定例の設定ファイル "conf.example-os-tts.toml" を "virtual-avatar-connect.exe" へドロップして VAC を起動してみましょう。
    <p class="info">
     コマンドラインでは `./virtual-avatar-connect conf.example-os-tts.toml` です。コマンドラインでの使い方は `--help` で確認できます。
    </p>
    <p>この設定ファイル "conf.example-os-tts.toml" の中身はこうなっています。👀</p>
    <textarea class="code" readonly style="height:23em">[[processors]]
channel_from = "user-ja"
feature = "OS-TTS"
voice_name = "Haruka"
tts_pitch = 1.0
tts_rate = 1.0
tts_volume = 1.0

[[processors]]
channel_from = "user-en"
feature = "OS-TTS"
voice_name = "Ayumi"
tts_pitch = 1.0
tts_rate = 1.0
tts_volume = 1.0</textarea>
   </li>
   <li class="hr"></li>
   <li>6-2. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a class="url">http://127.0.0.1:57000/input</a> を開きます。</li>
   <li>6-3. ブラウザーの別のウィンドウまたはタブへ 2-ch-mix 出力画面 <a class="url">http://127.0.0.1:57000/output/2-ch-mix#user-ja`user-en</a>
    を開きます。
    <p class="info"> 2-ch-mix など出力画面についてもっと知りたい場合は<a data-scrill-to="#output-screen">「使い方 12.
      「出力画面」の作り込み」</a>で紹介するので御覧ください。</p>
   </li>
   <li class="hr"></li>
   <li>6-4. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを user-ja に設定します。</li>
   <li>6-5. 入力内容に「こんにちは、VAC！」のように適当なメッセージを書きます。</li>
   <li>6-6. 送信チャンネルを設定した隣にある POST ボタンを押します。音声合成と再生が行われ、ついでに出力画面にも表示されます。 </li>
   <li class="hr"></li>
   <li>6-7. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを user-en に設定します。</li>
   <li>6-8. 入力内容に「Hello, VAC!」のように適当なメッセージを書きます。</li>
   <li>6-9. 送信チャンネルを設定した隣にある POST ボタンを押します。音声合成と再生が行われ、ついでに出力画面にも表示されます。</li>
  </ul>
 </div>

 <div class="info">
  <span>お使いの環境で《OS-TTS》から使用できる音声合成の一覧を確認したい場合は、コマンドラインで `./virtual-avatar-connect --test-os-tts`
   を実行すると表示とサンプル音声の再生が行われます。また version 0.2.0 からは <a class="url">http://127.0.0.1:57000/status</a>
   へアクセスすることでも《OS-TTS》の音声合成の一覧を確認できます。</span>
  </span>
  <p>Windows 11の場合は<a class="search">設定 時刻と言語 > 音声認識</a>から音声合成エンジンの管理を行えます。使いたい言語の音声パッケージを導入しましょう。</p>
  <div class="left-to-right-flex gap-1em">
   <iframe width="560" height="315" src="https://www.youtube.com/embed/1t-7SzkCCxk?si=_sNyDWdmnJf5bRT7"
    title="YouTube video player" frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen></iframe>
   <img src="image/m06/status-os-tts.png" class="img-show" style="max-width: calc(80vw - 560px)">
  </div>
 </div>

</section>








<section id="text-to-speech-coeiroink">
 <h1>
  <a><span data-scroll-to="#text-to-speech-os-tts">🔼</span></a>
  <a><span data-scroll-to="#text-to-speech-bouyomichan">🔽</span></a>
  使い方 7. （テキスト）→「音声合成」 // CoeiroInk編
 </h1>

 <p class="info">
  今回は 《CoeiroInk》 Processor を使用します。Processor は VAC に内蔵された入力と出力の間で流れる内容を変換したり、調整したりする主要な仕組みです。
  Processor を自由に組み合わせることでお好みのカスタム設定でVACを楽しめます。
 </p>

 <div class="info">《CoeiroInk》は <a class="url">https://coeiroink.com/</a> で公開されている「無料で使えるAIトークソフト」です。
  <ul>
   <li>日本語の音声合成が得意でとてもなめらかな音声をたくさんのキャラクターをベースに調整して利用できます。</li>
   <li>《OpenAI-Chat》プロセッサーでAI擬似人格共演者を実現したい場合におすすめの音声合成エンジンです。</li>
   <li>《MODify》プロセッサーでよみがな化すれば英語のコンテントも一応対応可能になります。</li>
  </ul>
 </div>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>7-1. CoeiroInk の準備 (導入済みの場合は飛ばして次へどうぞ)
    <p><a class="url">https://coeiroink.com/</a>の「ダウンロード」から CoeiroInk をダウンロードしてお使いの環境に導入します。</p>
    <p class="info">できるだけリアルタイムに応答を得たい方は「GPU版」を使うとよいです。</p>
   </li>
   <li>7-2. CoeiroInk を起動した状態で CoeiroInk の API が使用可能な状態か確認する <a class="url">http://127.0.0.1:50032/</a> にアクセスして
    {"status":"start"} と表示される状態を確認します。</li>
   <li class="hr"></li>
   <li>7-3. 《CoeiroInk》のシンプルな設定例の設定ファイル "conf.example-coeiroink.toml" を "virtual-avatar-connect.exe" へドロップして VAC
    を起動してみましょう。
    <p class="info">
     コマンドラインでは `./virtual-avatar-connect conf.example-coeiroink.toml` です。コマンドラインでの使い方は `--help` で確認できます。
    </p>
    <p>この設定ファイル "conf.example-coeiroink.toml" の中身はこうなっています。👀</p>
    <textarea class="code" readonly style="height:21em"># CoeiroInk デフォルト状態で音声合成
[[processors]]
feature = "coeiroink"
channel_from = "default"

# 話者とスタイルを指定して音声合成
[[processors]]
feature = "coeiroink"
channel_from = "genki"
# uuid や style_id は --coeiroink-speakers で表示できます。
speaker_uuid = "3c37646f-3881-5374-2a83-149267990abc"
style_id = 6
# 長い文章を受け取った場合にもできるだけリアルタイム性を維持して読ませたい場合に区切りを設定できます。
split_regex_pattern = "[、。！？]"</textarea>
   </li>
   <li class="hr"></li>
   <li>7-4. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a href="http://127.0.0.1:57000/input"
     target="_blank">http://127.0.0.1:57000/input</a> を開きます。</li>
   <li>7-5. ブラウザーの別のウィンドウまたはタブへ 2-ch-mix 出力画面 <a class="url">http://127.0.0.1:57000/output/2-ch-mix#default`genki</a>
    を開きます。
    <p class="info"> 2-ch-mix など出力画面についてもっと知りたい場合は<a data-scrill-to="#output-screen">「使い方 12.
      「出力画面」の作り込み」</a>で紹介するので御覧ください。</p>
   </li>
   <li class="hr"></li>
   <li>7-6. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを default に設定します。</li>
   <li>7-7. 入力内容に「こんばんは、こちらはデフォルトの音声です。」のように適当なメッセージを書きます。</li>
   <li>7-8. 送信チャンネルを設定した隣にある POST ボタンを押します。音声合成と再生が行われ、ついでに出力画面にも表示されます。 </li>
   <li class="hr"></li>
   <li>7-9. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを user-en に設定します。</li>
   <li>7-10. 入力内容に「元気スタイルです。もし長い文章が入力されても、短い単位に区切って合成し、読み上げながら逐次並行して次の単位を合成することでリアルタイム性をある程度維持できます。」のように適当なメッセージを書きます。
   </li>
   <li>7-11. 送信チャンネルを設定した隣にある POST ボタンを押します。音声合成と再生が行われ、ついでに出力画面にも表示されます。</li>
  </ul>
 </div>

 <div class="info">
  <span>お使いの環境で《CoeiroInk》で使用できる音声合成の話者やスタイルの一覧を確認したい場合は、コマンドラインで `./virtual-avatar-connect --coeiroink-speakers`
   を実行すると確認できます。また version 0.2.0 からは <a class="url">http://127.0.0.1:57000/status</a>
   へアクセスすることでも《CoeiroInk》の音声合成の一覧を確認できます。</span>
  </span>
  <div class="left-to-right-flex gap-1em">
   <img src="image/m07/coeiroink-speakers.png" class="img-show" style="max-width: 33vw">
   <img src="image/m07/status-coeiroink.png" class="img-show" style="max-width: 33vw">
  </div>
 </div>

</section>








<section id="text-to-speech-bouyomichan">
 <h1>
  <a><span data-scroll-to="#text-to-speech-coeiroink">🔼</span></a>
  <a><span data-scroll-to="#language-translation-gas">🔽</span></a>
  使い方 8. （テキスト）→「音声合成」 // 棒読みちゃん編
 </h1>

 <p class="info">
  今回は 《Bouyomichan》 Processor を使用します。Processor は VAC に内蔵された入力と出力の間で流れる内容を変換したり、調整したりする主要な仕組みです。
  Processor を自由に組み合わせることでお好みのカスタム設定でVACを楽しめます。
 </p>

 <div class="info">《Bouyomichan》は <a class="url">https://chi.usamimi.info/Program/Application/BouyomiChan/</a>
  で公開されている「漢字を含む日本語の文章を音声合成で読み上げるツール」です。
  <ul>
   <li>日本で一般に普及した音声合成ソフトの定番として長く愛されているソフトウェアです。</li>
   <li>歴史が長く、活用方法についての情報も調べやすいかもしれません。</li>
  </ul>
 </div>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>8-1. 棒読みちゃん の準備 (導入済みの場合は飛ばして次へどうぞ)
    <p><a class="url">https://chi.usamimi.info/Program/Application/BouyomiChan/</a>からダウンロードしてお使いの環境に導入し起動します。</p>
   </li>
   <li>8-2. 棒読みちゃんを配置したフォルダーの中の RemoteTalk フォルダーに入っている RemoteTalk.exe までのパスを確認します。(設定に必要になります。)
    <p class="info">例: C:\Program Files (x86)\BouyomiChan\RemoteTalk\RemoteTalk.exe</p>
   </li>
   <li class="hr"></li>
   <li>8-3. 《Bouyomichan》のシンプルな設定例の設定ファイル "conf.example-bouyomichan.toml" の remote_talk_path に (8-2.) で確認した
    RemoteTalk.exe までのパスを設定します。
    <p class="note">version 0.2.0 以前のダウンロード用パッケージには "conf.example-bouyomichan.toml" は同梱されていません。必要に応じて作成または、<a
      class="url">https://github.com/usagi/virtual-avatar-connect/blob/main/conf.example-bouyomichan.toml</a>からダウンロードしてご用意下さい。
    </p>
   </li>
   <li>8-4. 《Bouyomichan》のシンプルな設定例の設定ファイル "conf.example-bouyomichan.toml" を "virtual-avatar-connect.exe" へドロップして VAC
    を起動してみましょう。
    <p class="info">
     コマンドラインでは `./virtual-avatar-connect conf.example-bouyomichan.toml` です。コマンドラインでの使い方は `--help` で確認できます。
    </p>
    <p>この設定ファイル "conf.example-bouyomichan.toml" の中身はこうなっています。👀</p>
    <textarea class="code" readonly style="height:17em">[[processors]]
channel_from = "user"
feature = "bouyomichan"
# 棒読みちゃんをインストールしたフォルダーの中にあるRemoteTalk.exeのパスを設定して使います
remote_talk_path = 'C:\Users\the\Downloads\BouyomiChan_0_1_11_0_Beta21\RemoteTalk\RemoteTalk.exe'
address = "127.0.0.1"
port = 50001
voice = 2
speed = 68
tone = 133
volume = 100
</textarea>
   </li>
   <li class="hr"></li>
   <li>8-5. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a href="http://127.0.0.1:57000/input"
     target="_blank">http://127.0.0.1:57000/input</a> を開きます。</li>
   </li>
   <li>8-6. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを user に設定します。</li>
   <li>8-7. 入力内容に「こんばんは、棒読みちゃん。」のように適当なメッセージを書きます。</li>
   <li>8-8. 送信チャンネルを設定した隣にある POST ボタンを押します。音声合成と再生が行われ、ついでに出力画面にも表示されます。 </li>
  </ul>
 </div>

 <div class="info">
  <span>《Bouyomichan》で設定できる主なパラメーターは次の通りです。</span>
  <ul>
   <li>voice … 0:デフォルト 1:女性1 2:女性2 3:男性1 4:男性2 5:中性 6:ロボット 7:機械1 8:機械2 9以降:SAPI</li>
   <li>speed … -1:デフォルト 50:最低 300:最高</li>
   <li>tone … -1:デフォルト 50:最低 200:最高</li>
   <li>volume … -1:デフォルト 0:最低 100:最高</li>
  </ul>
 </div>

</section>






<section id="language-translation-gas">
 <h1>
  <a><span data-scroll-to="#text-to-speech-bouyomichan">🔼</span></a>
  <a><span data-scroll-to="#ai-pseudo-personality-openai">🔽</span></a>
  使い方 9. （テキスト）→「言語翻訳」→「テキスト表示」 // GAS編
 </h1>

 <p class="info">
  今回は 《GAS-Translation》 Processor を使用します。Processor は VAC に内蔵された入力と出力の間で流れる内容を変換したり、調整したりする主要な仕組みです。
  Processor を自由に組み合わせることでお好みのカスタム設定でVACを楽しめます。
 </p>

 <div class="info">《GAS-Translation》は <a class="search">Google Apps Script で翻訳</a> のように個人で使う程度なら誰でもおおむね実質無料枠だけで十分に使える<a
   href="">Google Apps Script</a>を使用した翻訳サービスをVAC連携で使用可能にするプロセッサーです。
  <ul>
   <li>とても多くの言語のわりと通じる翻訳を高速に提供できます。</li>
   <li><a href="http://www.sayonari.com/trans_asr/asr.html"
     target="jimakuchan">「音声認識字幕ちゃん」</a>と同じバックエンド方式を採用しています。翻訳用のGASが既にある場合は同じ Script ID をVACでもそのまま使用できます。</li>
  </ul>
 </div>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>9-1. Google Apps Script の準備 (翻訳用のGASを作成済みの場合は飛ばして次へどうぞ)
    <p>9-1-1. <a class="url">https://script.google.com/</a>にアクセスして「新しいプロジェクト」を作成します。</p>
    <p>9-1-2. 以下のコードを貼り付けて「プロジェクトを保存」(💾謎の古代の保存媒体のアイコンを押します)</p>
    <textarea class="code" readonly style="height:8em">function doGet(e) {
 const params = e.parameter
 var translatedText = LanguageApp.translate(params.text, params.source, params.target);
 const output = ContentService.createTextOutput();
 output.setMimeType(ContentService.MimeType.JSON);
 output.setContent(translatedText);
 return output;
}
</textarea>
    <p>9-1-3. 「デプロイ」→「新しいデプロイ」</p>
    <p>9-1-4. 「種類の選択 ⚙」（この⚙のところをクリック）→「ウェブアプリ」</p>
    <p>9-1-5. 「次のユーザーとして実行」が「自分」になっている事を確認</p>
    <p>9-1-5. 「アクセスできるユーザー」を「全員」に変更</p>
    <p>9-1-6. 「デプロイ」→「デプロイID」（= Script ID）をコピーして取得</p>
    <p class="info">以上のGAS翻訳サービスの作り方は<a href="http://www.sayonari.com/trans_asr/asr.html"
      target="jimakuchan">「音声認識字幕ちゃん」</a>を100%参考にさせて頂いています。先人に感謝いたします。🙏</p>
   </li>
   <li class="hr"></li>
   <li>9-2. 《GAS-Translation》のシンプルな設定例の設定ファイル "conf.example-gas-translation.toml" の script_id に (9-1.) で取得した
    GAS の Script ID を設定します。または、 Script ID の不慮の漏出に注意したい場合は環境変数 VAC_GAS_TRANSLATION_SCRIPT_ID に GAS の
    Script ID を設定しても動作します。お好みの方法で Script ID を設定して下さい。
    <p class="note">version 0.2.0 以前のダウンロード用パッケージには "conf.example-gas-translation.toml" は同梱されていません。必要に応じて作成または、<a
      class="url">https://github.com/usagi/virtual-avatar-connect/blob/main/conf.example-gas-translation.toml</a>からダウンロードしてご用意下さい。
    </p>
   </li>
   <li>9-3. 《GAS-Translation》のシンプルな設定例の設定ファイル "conf.example-gas-translation.toml" を "virtual-avatar-connect.exe" へドロップして
    VAC を起動してみましょう。
    <p class="info">
     コマンドラインでは `./virtual-avatar-connect conf.example-gas-translation.toml` です。コマンドラインでの使い方は `--help` で確認できます。
    </p>
    <p>この設定ファイル "conf.example-gas-translation.toml" の中身はこうなっています。👀</p>
    <textarea class="code" readonly style="height:17em">[[processors]]
channel_from = "user"
channel_to = "user-en"
feature = "gas-translation"
# Google Apps Script の Script ID
# 以下の script_id に GAS の Script ID を設定するか、環境変数 VAC_GAS_TRANSLATION_SCRIPT_ID に設定して下さい。
# script_id = "ここにあなたの Google Apps Script の ID を設定します（他人に公開しないようにご注意下さい）"
# 翻訳元の言語; 指定しないと自動推定になります。推定は万能ではないので、できるだけ指定することをおすすめします。
translate_from = "ja_JP"
# 翻訳先の言語
translate_to = "en_US"
</textarea>
   </li>
   <li class="hr"></li>
   <li>9-4. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a href="http://127.0.0.1:57000/input"
     target="_blank">http://127.0.0.1:57000/input</a> を開きます。</li>
   <li>9-5. ブラウザーの別のウィンドウまたはタブへ 2-ch-mix 出力画面 <a
     class="url">http://127.0.0.1:57000/output/2-ch-mix#user;;[日本語]`user-en;;[English]</a>
    を開きます。
    <p class="info"> 2-ch-mix など出力画面についてもっと知りたい場合は<a data-scrill-to="#output-screen">「使い方 12.
      「出力画面」の作り込み」</a>で紹介するので御覧ください。</p>
   </li>
   <li class="hr"></li>
   <li>9-6. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを user に設定します。</li>
   <li>9-7. 入力内容に「この入力内容は日本語から英語に自動的に翻訳されます。」のように適当なメッセージを書きます。</li>
   <li>9-8. 送信チャンネルを設定した隣にある POST ボタンを押します。音声合成と再生が行われ、ついでに出力画面にも表示されます。 </li>
  </ul>
 </div>

 <div class="info"><span>成功すると 2-ch-mix 出力画面は以下のような字幕が出力されます。</span>
  <img src="image/m09/ja-en.png" class="img-show" style="max-width: 40vw">
 </div>

</section>








<section id="ai-pseudo-personality-openai">
 <h1>
  <a><span data-scroll-to="#language-translation-gas">🔼</span></a>
  <a><span data-scroll-to="#modify">🔽</span></a>
  使い方 10. （テキスト）→「AI疑似人格」→「テキスト表示」 // OpenAI編
 </h1>

 <p class="info">
  今回は 《OpenAI-Chat》 Processor を使用します。Processor は VAC に内蔵された入力と出力の間で流れる内容を変換したり、調整したりする主要な仕組みです。
  Processor を自由に組み合わせることでお好みのカスタム設定でVACを楽しめます。
 </p>

 <div class="info">《OpenAI-Chat》は ChatGPT や DALL-E でお馴染みの OpenAI が提供する AI サービスをVAC連携で使用可能にするプロセッサーです。
  <ul>
   <li>PCに強力なGPUを搭載しても得難い超高度な AI を簡単に組み込めます。かわりに使いたい分だけ先払い制でお金がかかります。</li>
   <li>アカウント登録時に無料で18USD分のクレジットを貰えます。《OpenAI-Chat》のお試しには十二分な量なのでぜひ試してみて下さい。</li>
   <li>
    <em>ですます調で丁寧な受け答えのキャラクターなら安価で高速な「GPT3.5-Turbo」モデルで十分</em>です。こちらを使う場合には毎分1回応答させながら3時間程度ゲームプレイ配信しても0.06USD程度の使用料金です。もっと長時間使った場合でも、1000円の先払いで3ヶ月前後使えるかもしれません。
   </li>
   <li>
    <em>個性の強いキャラクターを作るには比較的高価な「GPT4」モデルが必要</em>です。こちらを使う場合は《OpenAI-Chat》の設定で応答を10分間隔＋キーワード応答に絞った運用で3時間程度のゲームプレイ配信で1.25USD程度の使用料金になります。こちらを使う場合は慎重に応答頻度の調整が必要です。
   </li>
  </ul>
 </div>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>10-1. OpenAI API の準備 (OpenAI API に登録済みの場合は飛ばして次へどうぞ)
    <p>10-1-1. <a class="url">https://openai.com/</a>にアクセスして "Log in↗" をクリックします。</p>
    <p>10-1-2. "Don't have an accout? Sign up" から "Sign up" をクリックします。</p>
    <p>10-1-3. <a class="url">https://platform.openai.com/account/usage</a> でAPI のクレジット残高を確認します。</p>
    <p>10-1-4. もし使用可能なクレジットが無ければ <a class="url">https://platform.openai.com/account/billing/overview</a> の "Add to
     credit balance" からクレジットを購入します。</p>
    <p>10-1.5. <a class="url">https://platform.openai.com/account/api-keys</a> で "Create new secret key" から API KEY
     を作成します。</p>
    <p class="note">
     OpenAIの"ChatGPT"と"API"は別のサービスで支払いも共有されません。OpenAIの有料サービスに初めて登録する方は気をつけて下さい。《OpenAI-Chat》に必要なサービスは"API"のみです。</p>
   </li>
   <li class="hr"></li>
   <li>10-2. 《OpenAI-Chat》のシンプルな設定例の設定ファイル "conf.example-openai-chat.toml" の api_key に (10-1.) で取得した
    OpenAI の API KEY を設定します。または、 API KEY の不慮の漏出に注意したい場合は環境変数 VAC_OPENAI_CHAT_API_KEY に OpenAI の
    API KEY を設定しても動作します。お好みの方法で API KEY を設定して下さい。
    <p class="note">version 0.2.0 以前のダウンロード用パッケージには "conf.example-openai-chat.toml" は同梱されていません。必要に応じて作成または、<a
      class="url">https://github.com/usagi/virtual-avatar-connect/blob/main/conf.example-openai-chat.toml</a>からダウンロードしてご用意下さい。
    </p>
   </li>
   <li>10-3. 《OpenAI-Chat》のシンプルな設定例の設定ファイル "conf.example-openai-chat.toml" を "virtual-avatar-connect.exe" へドロップして
    VAC を起動してみましょう。
    <p class="info">
     コマンドラインでは `./virtual-avatar-connect conf.example-openai-chat.toml` です。コマンドラインでの使い方は `--help` で確認できます。
    </p>
    <p>この設定ファイル "conf.example-openai-chat.toml" の中身はこうなっています。👀</p>
    <textarea class="code" readonly style="height:17em">[[processors]]
channel_from = "user"
channel_to = "ai"
feature = "openai-chat"
# OpenAI API の API KEY
# 以下の api_key に OpenAI API の API KEY を設定するか、環境変数 VAC_GAS_TRANSLATION_SCRIPT_ID に設定して下さい。
# api_key = "ここにあなたの OpenAI の API KEY を設定します（他人に公開しないようにご注意下さい）"

# 参考: https://platform.openai.com/docs/models/gpt-3-5
# 参考: https://platform.openai.com/docs/models/gpt-4
model = "gpt-3.5-turbo"
</textarea>
    <p class="info">《OpenAI-Chat》にはたくさんの設定項目があります。
     AIの広範な知識からの回答を得られる助手を召喚したいだけならサンプルの設定だけでも十分に楽しく、あるいは役立つよう動作してくれます。
     もっと高度な設定や疑似人格形成を行いたい場合はひとまず付属の conf.toml でコメントされている設定を参考にしてみてください。
     実際に開発のなかのひとが Twitch で配信する際に疑似人格ケルシー先生を構成するために使っている設定です。
     特に custom_instructions に疑似人格形成のための設定を書くことで、さまざまなAIキャラクターを構成できます。
     また、memory_capacity(応答ごとに過去何件分の記憶を擬似的に保持させるか), min_interval_in_secs(応答間隔), force_activate_regex_pattern(強制応答パターン),
     ignore_regex_pattern(無視パターン) などを適切に設定して AI の応答頻度を調整することも特に GPT4 を使う場合には大事です。
     他にも temperature, top_p, n, presence_penalty, frequency_penalty, max_tokens, user などの OpenAI API
     が受け取れるパラメーターは設定可能にしてあります。
    </p>
   </li>
   <li class="hr"></li>
   <li>10-4. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a href="http://127.0.0.1:57000/input"
     target="_blank">http://127.0.0.1:57000/input</a> を開きます。</li>
   <li>10-5. ブラウザーの別のウィンドウまたはタブへ 2-ch-mix 出力画面 <a
     class="url">http://127.0.0.1:57000/output/2-ch-mix#user;;[日本語]`ai;;[AI]</a>
    を開きます。
    <p class="info"> 2-ch-mix など出力画面についてもっと知りたい場合は<a data-scrill-to="#output-screen">「使い方 12.
      「出力画面」の作り込み」</a>で紹介するので御覧ください。</p>
   </li>
   <li class="hr"></li>
   <li>10-6. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを user に設定します。</li>
   <li>10-7. 入力内容に「この入力内容は日本語から英語に自動的に翻訳されます。」のように適当なメッセージを書きます。</li>
   <li>10-8. 送信チャンネルを設定した隣にある POST ボタンを押します。音声合成と再生が行われ、ついでに出力画面にも表示されます。 </li>
  </ul>
 </div>

 <div class="info"><span>成功すると 2-ch-mix 出力画面は以下のような字幕が出力されます。</span>
  <img src="image/m10/user-ai.png" class="img-show" style="max-width: 40vw">
  <p>
   ちなみに、2-ch-mixは基本的には同じ発言者の元の内容と翻訳の字幕を出力するように作られています。実際にAI疑似人格と配信を行う際には画面の左右でそれぞれ2-ch-mixを使ったり、上下に吹き出しを出す独自の出力画面を作ったりするとよいかもしれません。
  </p>
 </div>

</section>








<section id="modify">
 <h1>
  <a><span data-scroll-to="#ai-pseudo-personality-openai">🔼</span></a>
  <a><span data-scroll-to="#output-screen">🔽</span></a>
  使い方 11. （テキスト）→「MODify」→（テキスト） // 内容の加工や変換を行います
 </h1>

 <p class="info">
  今回は 《MODify》 Processor を使用します。Processor は VAC に内蔵された入力と出力の間で流れる内容を変換したり、調整したりする主要な仕組みです。
  Processor を自由に組み合わせることでお好みのカスタム設定でVACを楽しめます。
 </p>

 <p class="info">《MODify》は音声合成エンジンの直前に入れて、音声合成エンジンが読み間違えてしまう単語を読み間違えの無いようひらがなに変換する前処理や、
  《OCR》の結果から頻出する誤認識を修正したり、配信の字幕やAIの入力に使いたくない単語を伏せ字にしたり、地味に活躍するプロセッサーです。
 </p>

 <div class="flow">
  <h2>手順</h2>
  <ul>
   <li>11-1. 《MODify》のシンプルな設定例の設定ファイル "conf.example-modify.toml" を "virtual-avatar-connect.exe" へドロップして VAC
    を起動してみましょう。
    <p class="info">
     コマンドラインでは `./virtual-avatar-connect conf.example-modify.toml` です。コマンドラインでの使い方は `--help` で確認できます。
    </p>
    <p class="note">version 0.2.0 以前のダウンロード用パッケージには "conf.example-openai-chat.toml" は同梱されていません。必要に応じて作成または、<a
      class="url">https://github.com/usagi/virtual-avatar-connect/blob/main/conf.example-modify.toml</a>からダウンロードしてご用意下さい。
    </p>
    <p>この設定ファイル "conf.example-modify.toml" の中身はこうなっています。👀</p>
    <textarea class="code" readonly style="height:20em"># MODify は内容に変更を加えるプロセッサーです。
[[processors]]
channel_from = "user"
# from と to が同じ場合はこれ以降のプロセッサーへ流れる内容が完全に書き換えられます。
# from と to が異なる場合は変更した内容を to に送るだけの動作になります。
channel_to = "modified"

# 英単語をカタカナに変換
# 英語の文章を日本語の音声合成エンジンに読み上げさせる場合などに使うとアルファベットをそのまま読まれるよりはマシなこともあるかもしれません。
alkana = true

# この後に dictionary_files や regex_files がコメントでテンプレートとして用意されていますが
# 「使い方」の例では直接は紹介しないので興味がある方は conf.example-modify.toml を編集して試してみて下さい。
</textarea>
   </li>
   <li class="hr"></li>
   <li>11-2. VAC を起動します。 </li>
   <li>11-3. ブラウザーのウィンドウまたはタブへ標準の入力画面 <a class="url">http://127.0.0.1:57000/input</a> を開きます。</li>
   <li>11-4. ブラウザーの別のウィンドウまたはタブへ 2-ch-mix 出力画面 <a
     class="url">http://127.0.0.1:57000/output/2-ch-mix#user;;[user]`modified;;[mod]</a>
    を開きます。
    <p class="info"> 2-ch-mix など出力画面についてもっと知りたい場合は<a data-scrill-to="#output-screen">「使い方 12.
      「出力画面」の作り込み」</a>で紹介するので御覧ください。</p>
   </li>
   <li class="hr"></li>
   <li>11-5. 入力画面の上または下、今回はどちらでもよいので送信先のチャンネルを user に設定します。</li>
   <li>11-6. 入力内容に「Hello, Virtual Avatar Connect!」のように適当なメッセージを書きます。</li>
   <li>11-7. 送信チャンネルを設定した隣にある POST ボタンを押します。音声合成と再生が行われ、ついでに出力画面にも表示されます。 </li>
  </ul>
 </div>

 <div class="info"><span>成功すると 2-ch-mix 出力画面は以下のような字幕が出力されます。</span>
  <img src="image/m11/user-mod.png" class="img-show" style="max-width: 40vw">
  <p>
   《MODify》の alkana はそこそこの単語をカタカナにしてくれますが、意外と未登録の単語も多いので、もっとしっかりとカタカナにしたい場合は
   dictionary_files に辞書ファイルを追加してみて下さい。辞書ファイルは「Google 日本語入力」の辞書をエクスポートした.txtファイルも読み込めます。
   また、単純な辞書による置換では対応が難しい場合は regex_files に正規表現ファイルを追加してみて下さい。
  </p>
 </div>

</section>








<section id="output-screen">
 <h1>
  <a><span data-scroll-to="#modify">🔼</span></a>
  <a><span data-scroll-to="#input-screen">🔽</span></a>
  使い方 12. 「出力画面」の作り込み // 複数の出力画面をお好みでカスタムできます
 </h1>

 <div class="info">
  VACの「出力画面」"群"は OBS STUDIO などの配信アプリで表示することを想定した画面です。
  <ul>
   <li>VACの「出力画面」は「ブラウザーソース」での取り込みを想定しています。</li>
   <li>VACの「出力画面」は複数作成できます。</li>
   <li>VACの「出力画面」は一般的な HTML + CSS + JS や WASM でユーザーが独自に作り込めます。</li>
   <li>これまでの使い方に登場した標準の出力画面や2-ch-mix出力画面はVACを用いた画面作りのサンプルを兼ねています。ご自由に改変して自分だけの配信画面を作って頂いて構いません。👀</li>
  </ul>
 </div>

 <p class="note">
  VAC本体からのチャンネル出力情報はRESTまたはWebSocketで受信でき、両方に対応した簡単なライブラリーもサンプルに含まれています。
  おわかりになる方はその辺りから作り込んで頂いても構いませんし、 Vue.js や React などのフレームワークを使っても構いません。
  もちろん、素のHTMLやCSS、JS、WASMでサンプルを少しずつ改造したり、コピペしてアレンジ版を作るところから始めるのもよいと思います。
 </p>

 <div>
  <h2>配布状態の出力画面の構成</h2>

  <table>
   <tr>
    <th>.html ソースの場所</th>
    <th>動作中のURL</th>
    <th>概要</th>
   </tr>

   <tr class="top">
    <td class="nobr">output/index.html</td>
    <td class="nobr"><a class="url">http://127.0.0.1:57000/output</a></td>
    <td>
     <p>標準の出力画面、サンプルでは16:9で画面いっぱいにオーバーレイされる想定でさしあたりタイトルと副題を VAC の title, description チャンネルを受信して更新できるようになっています。</p>
     <p>また、出力画面単独でのシーン切り替えのサンプルも含まれていて、画面のクリックで BRB 画面へ切り替えられ、 BRB 画面でも brb チャンネルを受信して状況表示を更新できる仕組みになっています。</p>
     <p>ほかに loading シーンの素っ気ないレンプレートも含まれているので、出力画面単独でシーン切り替えしたくなったら参考にして下さい。</p>
    </td>
   </tr>

   <tr class="top">
    <td class="nobr">output/2-ch-mix.html</td>
    <td class="nobr"><a class="url">http://127.0.0.1:57000/output/2-ch-mix</a></td>
    <td>
     <p>上下に積み重なるように VAC から受信した2つのチャンネルを表示するパーツ単位の出力画面のサンプルです。</p>
     <p>表示する際にURLフラグメントでパラメーターを指定できるように仕込んであります。
      例えば /output/2-ch-mix#user;;[Dr.USAGI]`user-en;;[Dr.USAGI(transEN)] のようにURLフラグメントを付けて開くと、
      user チャンネルと user-en チャンネルを [Dr.USAGI] と [Dr.USAGI(transEN)] という話者表示のプリフィックス付きで表示します。</p>
     <p>他にも文字色の指定、C.V.表示などを行う想定のサフィックス表示にも対応しています。詳しくはソース冒頭の解説をどうぞ。</p>
    </td>
   </tr>

   <tr class="top">
    <td class="nobr">output/*.html</td>
    <td class="nobr">http://127.0.0.1:57000/output/*</td>
    <td>
     <p>2-ch-mixと同様に、 output/ に .html ファイルがあれば VAC は出力画面として読み込めるように扱います。</p>
     <p>例えば、 my-out1.html というファイルを作成して output/ へ配置すれば、 http://127.0.0.1:57000/my-out1 という出力画面として動作します。</p>
     <p>少し下で紹介する「配布状態のVAC出力画面向けAPIの簡単な使い方」なども参考に、自分だけの出力画面を作り込んで下さい。</p>
    </td>
   </tr>

   <tr class="top">
    <td class="nobr">resources/**/*</td>
    <td class="nobr">http://127.0.0.1:57000/resources/**/*</td>
    <td>
     <p>ソースのoutput/ は .html ファイルのみを扱います。他に出力画面から参照させたいファイルがある場合は resources/ へ配置します。</p>
     <p>resource/ は出力画面、入力画面いずれからも共通でアクセスできるファイル置き場です。</p>
     <p>主に CSS, js, wasm, 画像, 音声, 動画などのファイルを配置して使います。</p>
    </td>
   </tr>

  </table>
 </div>

 <div class="flow">
  <h2>配布状態のVAC出力画面向けAPIの簡単な使い方（一般的におすすめ）</h2>

  <ul>
   <li>出力画面用の .html に script 要素を追加して type="module" で src="resources/js/output.js" をロードします。</li>
   <li>チャンネルから受信した内容を表示したいHTML要素を作り data-vac-output="title" のように受信したいチャンネルを指定します。</li>
   <li>.html に script 要素を追加して document.addEventListener('DOMContentLoaded', () => vac.output.run()) とおまじないを書きます。</li>
  </ul>

  <textarea style="height:5em">
   <script type="module" src="/resources/js/output.js"></script>
   <script>document.addEventListener('DOMContentLoaded', () => vac.output.run())</script>
   <span data-vac-output="title">受信する前にも何か表示しておきたかったら何か書いておきます。</span>
  </textarea>

  <p class="info">出力画面からもっと細かく API を使いたい場合は resources/js/output.js や resources/js/api.js を参考にするとよいかもしれません。👀</p>
 </div>

 <div class="flow">
  <h2>VAC本体から直接チャンネル出力情報を取得する使い方（⚠️高度な応用をしたい方向け）</h2>
  <p>WebSocket: ws://127.0.0.1:57000/ へ接続し、受信した payload を JSON デコードします。</p>
  <p>REST: http://127.0.0.1:57000/output に POST で body に OutputRequestPayload 構造体を JSON 形式で入れて投げ、応答から JSON 化された
   OutputResponsePayload を受け取ります。</p>
  <div class="left-to-right-flex">
   <textarea style="width:44%;margin-right:2em">// for REST /output POST Request

#[derive(Deserialize, Debug)]
struct OutputRequestPayload {
 // 受信したいチャンネルのリスト
 channels: Vec<ChannelRequest>,
}

#[derive(Deserialize, Debug)]
struct ChannelRequest {
 // 受信したいチャンネル名
 name: String,
 // 既に取得済みの ID を与えると、その ID 以降の内容を取得します。
 retrieved_id: Option<u64>,
 // 既に取得済みの iso8601 日時を与えると、その日時以降の内容を取得します。
 retrieved_timestamp: Option<String>,
 // 取得する最大件数を指定します。
 count: Option<usize>,
}</textarea>
   <textarea style="width:44%">// for REST /output POST Response & WebSocket Message

#[derive(Serialize, Debug)]
struct OutputResponsePayload {
 /// チャンネル名 -> チャンネルデータ
 channel_data: HashMap<String, Vec<ChannelDatum>>,
}

#[derive(Serialize, Debug)]
struct ChannelDatum {
 /// Datum ID
 id: Option<u64>,
 /// ISO8601 日時
 datetime: Option<String>,
 /// チャンネル名
 channel: Option<String>,
 /// 内容
 content: Option<String>,
 /// フラグ
 #[serde(default)]
 flags: HashSet<String>,
}</textarea>

  </div>
 </div>

</section>








<section id="input-screen">
 <h1>
  <a><span data-scroll-to="#output-screen">🔼</span></a>
  <a><span data-scroll-to="#system-and-keywords">🔽</span></a>
  使い方 13. 「入力画面」をお好みに // 複数の入力画面をお好みでカスタムできます
 </h1>

 <div class="info">
  VACの「入力画面」"群"は音声認識や簡易版の画像認識、あるいはキーボードによるチャンネルへの入力を行うユーザーインターフェースとなる画面です。
  <ul>
   <li>VACの「出力画面」は複数作成できます。</li>
   <li>VACの「入力画面」は一般的な HTML + CSS + JS や WASM でユーザーが独自に作り込めます。</li>
   <li>出力画面のようにブラウザーソース向けにパーツや構成を複数作ることはないかもしれませんが、自分なりの使い方のモードや特定の端末やディスプレイに特化した入力画面を作るのもよいかもしれません。👀</li>
  </ul>
 </div>

 <p class="note">VAC本体へのチャンネル入力情報はRESTまたはWebSocketで送信できます。</p>

 <div>
  <h2>配布状態の入力画面の構成</h2>

  <table>
   <tr>
    <th>.html ソースの場所</th>
    <th>動作中のURL</th>
    <th>概要</th>
   </tr>

   <tr class="top">
    <td class="nobr">input/index.html</td>
    <td class="nobr"><a class="url">http://127.0.0.1:57000/input</a></td>
    <td>
     <p>標準の入力画面、上部に音声認識入力、下部に簡易版の画像認識による入力インターフェースを備えています。</p>
    </td>
   </tr>

   <tr class="top">
    <td class="nobr">input/*.html</td>
    <td class="nobr">http://127.0.0.1:57000/input/*</td>
    <td>
     <p>input/ に .html ファイルがあれば VAC は出力画面として読み込めるように扱います。</p>
     <p>例えば、 my-in1.html というファイルを作成して input/ へ配置すれば、 http://127.0.0.1:57000/my-in1 という入力画面として動作します。</p>
     <p>少し下で紹介する「配布状態のVAC入力画面向けAPIの簡単な使い方」なども参考に、自分だけの出力画面を作り込んで下さい。</p>
    </td>
   </tr>

   <tr class="top">
    <td class="nobr">resources/**/*</td>
    <td class="nobr">http://127.0.0.1:57000/resources/**/*</td>
    <td>
     <p>ソースのinput/ は .html ファイルのみを扱います。他に入力画面から参照させたいファイルがある場合は resources/ へ配置します。</p>
     <p>resource/ は出力画面、入力画面いずれからも共通でアクセスできるファイル置き場です。</p>
     <p>主に CSS, js, wasm, 画像, 音声, 動画などのファイルを配置して使います。</p>
    </td>
   </tr>

  </table>
 </div>

 <div class="flow">
  <h2>VAC本体へチャンネル入力情報を送信する方法</h2>
  <p>WebSocket: ws://127.0.0.1:57000/ へ接続し、 InputPayload 構造体をJSON形式の文字列値として送信します。</p>
  <p>REST: http://127.0.0.1:57000/input に POST で body に InputPayload 構造体を JSON 形式で入れて投げます。</p>
  <textarea>// for REST /input POST Request & WebSocket Message

#[derive(Serialize, Deserialize, Debug, Clone)]
struct InputPayload {
 /// チャンネル名
 channel: String,
 /// 内容
 content: String,
 /// 入力途中なら false, 確定済みで内容が変化しないなら true
 is_final: bool,
}</textarea>
 </div>

</section>








<section id="system-and-keywords">
 <h1>
  <a><span data-scroll-to="#input-screen">🔼</span></a>
  <!-- <a><span data-scroll-to="#">🔽</span></a> -->
  使い方 X. ふろく: VAC の仕組みと用語
 </h1>

 <section>
  <h2>VACの仕組み</h2>

  <p>すごーく大雑把に描くとだいたい下図のような具合になっています。</p>

  <div class="left-to-right-flex">
   <img src="image/x/system-over.png" class="img-show" style="max-width: 33vw; max-height: none; margin-right: 1em">
   <img src="image/x/system-inner.png" class="img-show" style="max-width: 33vw; max-height: none">
  </div>

  <ul>
   <li>VACはWebインターフェースとしてWebSocketを含むHTTPdを内蔵していて、ユーザーからの入力画面やOBS STUDIOなどへの出力画面はWebインターフェースを通して行います。</li>
   <li>VAC内部では設定ファイルで定義された《Processor》群を、設定で定義された分だけそれぞれ実体化して入力を待ち受けます。</li>
   <li>チャンネルへコンテントの入力が行われると、そのチャンネルを処理対象(channel_from)とした《Processor》が設定で上の方で定義された順に入力を処理します。</li>
   <li>《Processor》は入力を加工したり、入力に応じてバックエンドAPIを呼び出して新たなコンテントを生成したりします。</li>
   <li>《Processor》は出力設定があれば、その出力設定に応じて加工したり生成したりしたコンテントを設定されたチャンネルへ送出します。</li>
   <li>もとの入力は通常は次の《Processor》にも流れ、設定ファイルで定義されたすべての《Processor》が入力を同様に処理します。</li>
   <li>
    多くの《Processor》は入力に対する前処理が終わるとメインの処理は非同期処理ブロックへ逃がす作りになっているので、同じチャンネルに《Processor》をたくさん設定してもそこそこ大丈夫かもしれません。(お使いのPCと設定のworkersによります。)
   </li>
  </ul>

 </section>

 <section>

  <h2>VACの用語</h2>

  <section>
   <h3>Processor</h3>
   <ul>
    <li>Processor （プロセッサー）は VAC のチャンネルに流れる内容を受け取り、連携アプリと情報をやり取りしたり、内容を加工したり、別のチャンネルへ出力したりする仕組みです。</li>
    <li>Processor はチャンネルごとにお好みの順序で、お好みの設定で繋げて使用できます。</li>
    <li>同じ種類の Processor を1度だけ使うことも、繰り返し繋いで使うことももできます。</li>
   </ul>
   <p class="info">VACの使い方の解説ではプロセッサーを《Screenshot》のように表記します。設定ファイルで feature = "Screenshot" と書く部分はこの名前を使います。</p>
  </section>

  <section>
   <h3>AI疑似人格共演者</h3>
   <ul>
    <li>《OpenAI-Chat》を使い、channel_from にユーザーの音声入力を割り当てるなどして、AIを擬似的な人格を持った共演者として配信などに出演して貰うことを表現しています。</li>
    <li>特に、GPT4モデルやCoeiroInkを併用することで、わりと楽しくリアリティーもそこそこな共演者さんに登場して貰えます。但しGPT4はAPI使用料金が高めなのでそこは本当に気をつけて下さい。</li>
   </ul>
   <p class="info">実際に<a href="https://www.twitch.tv/usaginetwork" target="_blank">開発のなかのひとの Twitch 配信で「Dr.USAGIとケルシー先生のゲームお楽しみ配信」のような形でAI疑似人格共演者を召喚して一緒にゲームプレイ配信</a>をしています。気が向いたらご視聴下さい。👀</p>
  </section>

 </section>

</section>








<div class="dark-mode-switch hud" title="ライトモード/ダークモード">
 <div class="toggle-switch" onclick="force_dark_mode(!this.querySelector('input').checked)">
  <input type="checkbox" class="force-dark-mode">
  <label></label>
 </div>
</div>








<div class="scroll-to hud" title="目的地へスクロール">
 <div data-scroll-to="body">⏫トップ</div>
 <div data-scroll-to="#usage">📖使い方</div>
</div>

<div class="img-show-case">
 <div>
  <img>
 </div>
</div>